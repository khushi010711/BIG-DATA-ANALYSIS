import pandas as pd
import dask.dataframe as dd
import numpy as np

# Step 1: Simulate a large dataset
np.random.seed(42)

n_rows = 1_000_000  # 1 million rows

products = ['Laptop', 'Phone', 'Tablet', 'Monitor', 'Keyboard']
customers = ['Alice', 'Bob', 'Charlie', 'Diana', 'Eve']

data = {
    'order_id': np.arange(n_rows),
    'product': np.random.choice(products, size=n_rows),
    'customer': np.random.choice(customers, size=n_rows),
    'quantity': np.random.randint(1, 5, size=n_rows),
    'price_per_unit': np.random.uniform(50, 1500, size=n_rows)
}

df = pd.DataFrame(data)
df['total_price'] = df['quantity'] * df['price_per_unit']

# Step 2: Convert to Dask DataFrame
ddf = dd.from_pandas(df, npartitions=10)

# Step 3: Total sales per product
sales_by_product = ddf.groupby('product')['total_price'].sum().compute().sort_values(ascending=False)
print("Total Sales by Product:\n", sales_by_product)

# Step 4: Average order value by customer
avg_order_by_customer = ddf.groupby('customer')['total_price'].mean().compute().sort_values(ascending=False)
print("\nAverage Order Value by Customer:\n", avg_order_by_customer)

# Step 5: Most frequently purchased products
product_counts = ddf['product'].value_counts().compute()
print("\nProduct Purchase Frequency:\n", product_counts)

# Step 6: Save output (optional)
sales_by_product.to_csv("sales_by_product.csv")
avg_order_by_customer.to_csv("avg_order_value_by_customer.csv")
